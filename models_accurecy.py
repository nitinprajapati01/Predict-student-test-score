# -*- coding: utf-8 -*-
"""pm-2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1FEEZvNB_JqmBoAzTOhU83FdBje0NV65o
"""

import numpy as np 
import pandas as pd

import os

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.model_selection import GridSearchCV
from sklearn.model_selection import KFold
from sklearn.model_selection import StratifiedKFold
from sklearn.model_selection import cross_val_score, cross_validate
from sklearn.model_selection import RandomizedSearchCV
from sklearn.metrics import accuracy_score
from sklearn.metrics import mean_absolute_error
from sklearn.ensemble import RandomForestRegressor
from sklearn.tree import DecisionTreeClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.linear_model import LinearRegression
from sklearn.linear_model import LassoCV
from sklearn.tree import DecisionTreeRegressor
from sklearn.svm import SVR
from sklearn.ensemble import RandomForestRegressor
from sklearn.ensemble import GradientBoostingRegressor
from xgboost import XGBRegressor
import lightgbm 
from sklearn.ensemble import AdaBoostRegressor
import tensorflow as tf
from sklearn.metrics import mean_squared_error
from math import sqrt
from sklearn.preprocessing import StandardScaler
from tensorflow.keras.layers import Input, Dense, Activation,Dropout
from tensorflow.keras.models import Model
from sklearn.metrics import explained_variance_score, mean_absolute_error

df = pd.read_csv("test_scores.csv")

print(df.head())

print(df.describe())

print(df.isnull().sum())

print(df.dtypes)

print(df.school.unique())

corr = df.corr()
print(corr)

sns.heatmap(corr, annot=True, linewidth=.5, linecolor="red")
plt.show()

for x in ["school"]:
    for val in df[x].unique():
        count = df[x].value_counts()[val]
        percent = df[x].value_counts(normalize=True)[val] * 100
        print(f"{val} - Count: {count}, Percentage: {percent:.2f}%")
    print()

for x in ["school_setting", "school_type", "teaching_method", "gender", "lunch"]:
    for val in df[x].unique():
        count = df[x].value_counts()[val]
        percent = df[x].value_counts(normalize=True)[val] * 100
        print(f"{val} - Count: {count}, Percentage: {percent:.2f}%")

sns.distplot(df["n_student"], color = 'red')

sns.distplot(df["pretest"], color = 'green')

sns.distplot(df["posttest"], color = 'blue')

sns.distplot(df[["pretest","posttest"]], color = 'magenta')

sns.pairplot(df, x_vars=["n_student"], y_vars=["posttest"],height=8, aspect=1.5, kind="reg");

sns.pairplot(df, x_vars=["n_student"], y_vars=["pretest"],height=8, aspect=1.5, kind="reg");

sns.displot(df, x="pretest", hue="n_student", kind="kde",palette="Set2")

sns.displot(df, x="posttest", hue="n_student", kind="kde",palette="Set2")

sns.lmplot(x="pretest", y="posttest", hue="n_student", col="school", data=df, palette="Set2");

sns.lmplot(x="pretest", y="posttest", hue="n_student", col="school_setting", data=df, palette="Set2");

sns.relplot(x="pretest", y="posttest", hue="n_student", col="gender", data=df,  palette="Set2");

sns.relplot(x="pretest", y="posttest", hue="n_student", col="teaching_method", kind="scatter", data=df, palette="Set2");

sns.barplot(x="n_student", y="pretest", hue="lunch",data=df,palette="Set2");

sns.barplot(x="n_student", y="posttest", hue="lunch",data=df,palette="Set2");

sns.relplot(x="n_student", y="pretest", hue="gender",style="lunch",col="teaching_method", ci=None, kind="line", data=df, palette="Set2");

sns.relplot(x="n_student", y="posttest", hue="gender", style="lunch",col="teaching_method", ci=None, kind="line", data=df, palette="Set2");

sns.pairplot(df[['school_setting', 'school_type', 'teaching_method', 'n_student', 'gender', 'lunch', 'pretest', 'posttest']])

sns.pairplot(df[['school_setting', 'school_type', 'teaching_method', 'n_student', 'gender', 'lunch', 'pretest', 'posttest']], kind="kde")

df2 = df.drop(['classroom','student_id'], axis = 1)
print(df2.head())

features = pd.get_dummies(df2)
features.rename(columns = {'school_type_Non-public' : 'school_type_Non_public','lunch_Does not qualify':'lunch_Does_not_qualify', 'lunch_Qualifies for reduced/free lunch':'lunch_Qualifies_for_reduced/free_lunch'}, inplace = True)
print(features.head())

X = features.drop('posttest', axis=1)
y = features["posttest"]
print(y.head())

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
print(X_train)
print(X_train)
print(y_train)
print(y_train)

def test_score(y_test, y_pred):
    """Helper function for evaluation metrics."""
    accuracy = explained_variance_score(y_test, y_pred) * 100
    mae = round(mean_absolute_error(y_test, y_pred), 2)
    print(f"""accuracy: {accuracy:.2f}""")
    print(f"""MAE: {mae:.2f}""")
    return accuracy

accuracy_scores = np.zeros(5, dtype="float64")

#Linear Regression
reg = LinearRegression().fit(X_train, y_train)
y_pred = reg.predict(X_test)
accuracy_scores[0] = test_score(y_test, y_pred)

#Lasso Regression
reg1 = LassoCV().fit(X_train, y_train)
y_pred1 = reg1.predict(X_test)
accuracy_scores[1] = test_score(y_test, y_pred1)

#Random Forest Regressor
reg4 = RandomForestRegressor().fit(X_train, y_train)
y_pred4 = reg4.predict(X_test)
accuracy_scores[2] = test_score(y_test, y_pred4)

#XGBoost Regressor
xg_model = XGBRegressor()
xg_model.fit(X_train, y_train)
xg_pred = xg_model.predict(X_test)
accuracy_scores[3] = test_score(y_test, xg_pred)

#Regression with Tensorflow - Nueral Network
sc = StandardScaler()
X_train = sc.fit_transform(X_train)
X_test = sc.transform(X_test)
input_layer = Input(shape=(X.shape[1],))
dense_layer_1 = Dense(100, activation='relu')(input_layer)
dense_layer_2 = Dense(50, activation='relu')(dense_layer_1)
dense_layer_3 = Dense(25, activation='relu')(dense_layer_2)
output = Dense(1)(dense_layer_3)
model = Model(inputs=input_layer, outputs=output)
model.compile(loss="mean_squared_error" , optimizer="adam", metrics=["mae"])

print(model.summary())

history = model.fit(X_train, y_train, batch_size=128, epochs=100, verbose=1, validation_split=0.2)

model.evaluate(X_test, y_test)

tensor_pred = model.predict(X_test)
accuracy_scores[4] = test_score(y_test, tensor_pred)

sns.set_style('whitegrid')

models = ["Linear Regression","Lasso Regression","Random Forest Regression","XGBoost Regression","Nueral Network"]


plt.figure(figsize=(11, 11))
sns.barplot(x=accuracy_scores, y=models)


plt.xlabel("Model_Name")
plt.xticks(rotation = -90)
plt.ylabel("Accuracy")

plt.show()